// /api/daily-refresh.js (Refactored for Multi-PMS Forecasting)
const pgPool = require("./utils/db");
const cloudbedsAdapter = require("./adapters/cloudbedsAdapter.js");
// Import the mewsAdapter so we can use its functions.
const mewsAdapter = require("./adapters/mewsAdapter.js");
const format = require("pg-format");

module.exports = async (request, response) => {
  // ** REFACTORED LOGIC **
  // The job now fetches all connected properties directly, making it property-centric
  // instead of user-centric. This is more robust.
  console.log("Starting daily FORECAST refresh job for ALL PROPERTIES...");
  let totalRecordsUpdated = 0;

  try {
    // More descriptive logging for the job's purpose.
    console.log("Starting daily forecast refresh job for all properties...");
    let totalRecordsUpdated = 0;

    // Step 1: Get a list of all hotels and their essential info.
    // This is more efficient as it's one query for all properties.
    // It also fetches the pms_type and timezone needed for branching.
    const propertiesResult = await pgPool.query(
      // /api/daily-refresh.js

      "SELECT hotel_id, pms_property_id, property_name, pms_type, timezone, tax_rate, tax_type FROM hotels"
    );
    const allProperties = propertiesResult.rows;
    console.log(`Found ${allProperties.length} properties to process.`);

    // Step 2: Loop through each property.
    for (const hotel of allProperties) {
      const {
        hotel_id,
        property_name,
        pms_type,
        timezone,
        tax_rate,
        tax_type,
      } = hotel;
      console.log(
        `--- Processing: ${property_name} (ID: ${hotel_id}, PMS: ${pms_type}) ---`
      );

      let processedData; // This will hold the forecast data from the adapter.

      // /api/daily-refresh.js

      // Branch logic based on the property's PMS type.
      if (pms_type === "cloudbeds") {
        try {
          // THE FIX: Determine the correct ID to use for the Cloudbeds API.
          // For new hotels, this will be pms_property_id.
          // For old hotels, it will fall back to hotel_id, which is correct for them.
          const cloudbedsApiId = hotel.pms_property_id || hotel.hotel_id;

          // getAccessToken correctly uses our internal hotel_id to find credentials.
          const accessToken = await cloudbedsAdapter.getAccessToken(hotel_id);
          const pricingModel = tax_type || "inclusive";

          // Call the Cloudbeds adapter with the correct ID for their API.
          processedData = await cloudbedsAdapter.getUpcomingMetrics(
            accessToken,
            cloudbedsApiId,
            tax_rate,
            pricingModel
          );
        } catch (err) {
          console.error(
            `-- Failed to fetch Cloudbeds data for ${property_name}. Error: --`,
            err.message
          );
          continue; // Skip to the next hotel.
        }
      } else if (pms_type === "mews") {
        try {
          // Get Mews credentials from the database.
          const credsResult = await pgPool.query(
            "SELECT pms_credentials FROM user_properties WHERE property_id = $1 LIMIT 1",
            [hotel_id]
          );
          const credentials = credsResult.rows[0]?.pms_credentials;
          if (!credentials) {
            throw new Error(
              `No Mews credentials found for property ${hotel_id}.`
            );
          }

          const dataMap = {};
          let currentStartDate = new Date();
          const finalEndDate = new Date();
          finalEndDate.setDate(currentStartDate.getDate() + 365);

          // Loop through the next 365 days in 90-day chunks to respect API limits.
          while (currentStartDate < finalEndDate) {
            let currentEndDate = new Date(currentStartDate);
            currentEndDate.setDate(currentEndDate.getDate() + 89); // Fetch in ~90 day chunks

            if (currentEndDate > finalEndDate) {
              currentEndDate = finalEndDate;
            }

            const startDateStr = currentStartDate.toISOString().split("T")[0];
            const endDateStr = currentEndDate.toISOString().split("T")[0];

            console.log(
              `-- Fetching Mews forecast chunk from ${startDateStr} to ${endDateStr}... --`
            );

            const [occupancyData, revenueData] = await Promise.all([
              mewsAdapter.getOccupancyMetrics(
                credentials,
                startDateStr,
                endDateStr,
                timezone
              ),
              mewsAdapter.getRevenueMetrics(
                credentials,
                startDateStr,
                endDateStr,
                timezone
              ),
            ]);

            // Merge the data from this chunk into our main dataMap.
            occupancyData.dailyMetrics.forEach((metric) => {
              dataMap[metric.date] = {
                ...dataMap[metric.date],
                rooms_sold: metric.occupied,
                capacity_count: metric.available,
              };
            });
            revenueData.dailyMetrics.forEach((metric) => {
              dataMap[metric.date] = {
                ...dataMap[metric.date],
                net_revenue: metric.netRevenue,
                gross_revenue: metric.grossRevenue,
              };
            });

            // Advance the start date for the next loop iteration.
            currentStartDate.setDate(currentStartDate.getDate() + 90);
          }

          // Calculate the final derived metrics for each day after all chunks are fetched.
          for (const date in dataMap) {
            const metrics = dataMap[date];
            metrics.occupancy =
              metrics.capacity_count > 0 && metrics.rooms_sold
                ? metrics.rooms_sold / metrics.capacity_count
                : 0;
            metrics.net_adr =
              metrics.rooms_sold > 0 && metrics.net_revenue
                ? metrics.net_revenue / metrics.rooms_sold
                : 0;
            metrics.gross_adr =
              metrics.rooms_sold > 0 && metrics.gross_revenue
                ? metrics.gross_revenue / metrics.rooms_sold
                : 0;
            metrics.net_revpar =
              metrics.capacity_count > 0 && metrics.net_revenue
                ? metrics.net_revenue / metrics.capacity_count
                : 0;
            metrics.gross_revpar =
              metrics.capacity_count > 0 && metrics.gross_revenue
                ? metrics.gross_revenue / metrics.capacity_count
                : 0;
          }

          processedData = dataMap;
        } catch (err) {
          console.error(
            `-- Failed to fetch Mews forecast for ${property_name}. Error: --`,
            err.message
          );
          continue;
        }
      } else {
        console.log(
          `-- Unknown PMS type '${pms_type}' for hotel ${property_name}. Skipping. --`
        );
        continue; // Skip unknown PMS types.
      }

      const datesToUpdate = Object.keys(processedData);

      if (datesToUpdate.length > 0) {
        const client = await pgPool.connect();
        try {
          await client.query("BEGIN");

          // Find a cloudbeds_user_id for the property, required by the legacy DB schema.
          // NOTE: This can be removed once cloudbeds_user_id is removed from the table.
          const userResult = await client.query(
            "SELECT user_id FROM user_properties WHERE property_id = $1 LIMIT 1",
            [hotel_id]
          );
          const cloudbedsUserId =
            userResult.rows.length > 0 ? userResult.rows[0].user_id : null;

          const bulkInsertValues = datesToUpdate.map((date) => {
            const metrics = processedData[date];
            // This data structure matches what both adapters will return.
            return [
              date,
              hotel_id,
              metrics.rooms_sold || 0,
              metrics.capacity_count || 0,
              cloudbedsUserId, // Legacy column
              metrics.net_revenue || 0,
              metrics.gross_revenue || 0,
              metrics.net_adr || 0,
              metrics.gross_adr || 0,
              metrics.net_revpar || 0,
              metrics.gross_revpar || 0,
            ];
          });

          // This single query works for both Cloudbeds and Mews data.
          // Note: occupancy_direct is no longer populated as it was a calculated field.
          const query = format(
            `INSERT INTO daily_metrics_snapshots (stay_date, hotel_id, rooms_sold, capacity_count, cloudbeds_user_id, net_revenue, gross_revenue, net_adr, gross_adr, net_revpar, gross_revpar)
             VALUES %L
             ON CONFLICT (hotel_id, stay_date) DO UPDATE SET
                 rooms_sold = EXCLUDED.rooms_sold,
                 capacity_count = EXCLUDED.capacity_count,
                 cloudbeds_user_id = EXCLUDED.cloudbeds_user_id,
                 net_revenue = EXCLUDED.net_revenue,
                 gross_revenue = EXCLUDED.gross_revenue,
                 net_adr = EXCLUDED.net_adr,
                 gross_adr = EXCLUDED.gross_adr,
                 net_revpar = EXCLUDED.net_revpar,
                 gross_revpar = EXCLUDED.gross_revpar;`,
            bulkInsertValues
          );

          await client.query(query);
          await client.query("COMMIT");

          totalRecordsUpdated += datesToUpdate.length;
          console.log(
            `-- Successfully updated ${datesToUpdate.length} forecast records for ${property_name}. --`
          );
        } catch (e) {
          await client.query("ROLLBACK");
          console.error(
            `-- DB update failed for ${property_name}. Error: --`,
            e.message
          );
        } finally {
          client.release();
        }
      } else {
        console.log(
          `-- No new forecast records to update for ${property_name}. --`
        );
      }
    }

    // Update the system_state table to record that the job ran successfully.
    console.log(
      "✅ Daily forecast refresh job complete. Updating system_state table..."
    );
    const jobData = { timestamp: new Date().toISOString() };
    // THE FIX: Corrected the key to match what the dashboard API endpoint reads.
    await pgPool.query(
      "INSERT INTO system_state (key, value) VALUES ($1, $2) ON CONFLICT (key) DO UPDATE SET value = $2;",
      ["last_successful_refresh", jobData]
    );
    console.log("System state updated successfully.");

    response.status(200).json({
      status: "Success",
      processedProperties: allProperties.length,
      totalRecordsUpdated: totalRecordsUpdated,
    });
  } catch (error) {
    console.error("CRON JOB FAILED:", error);
    response.status(500).json({ status: "Failure", error: error.message });
  }
};
